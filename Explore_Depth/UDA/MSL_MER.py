import numpy as np
from skimage import io
from glob import glob
from tqdm import tqdm_notebook as tqdm
from sklearn.metrics import confusion_matrix
import random
import itertools
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils import model_zoo
import torch.utils.data as data
import torch.optim as optim
import torch.nn.init
from torch.autograd import Variable
from IPython.display import clear_output
import os
import time
from utils_M import *
from transdiscri import transDiscri
from FTUNetFormer_11 import ft_unetformer as ViT_seg
from func import loss_calc, bce_loss
from loss import entropy_loss
from func import prob_2_entropy
import torch.backends.cudnn as cudnn
import random
import matplotlib.pyplot as plt

def seed_torch(seed=1034):
	random.seed(seed)
	os.environ['PYTHONHASHSEED'] = str(seed) # 为了禁止hash随机化，使得实验可复现
	np.random.seed(seed)
	torch.manual_seed(seed)
	torch.cuda.manual_seed(seed)
	torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.
	torch.backends.cudnn.benchmark = False
	torch.backends.cudnn.deterministic = True

seed_torch()

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

try:
    from urllib.request import URLopener
except ImportError:
    from urllib import URLopener


# Parameters

WINDOW_SIZE = (256, 256) # Patch size


STRIDE = 32 # Stride for testing
IN_CHANNELS = 3 # Number of input channels (e.g. RGB)
FOLDER = "/data5/GLGAN/datasets/" # Replace with your "/path/to/the/ISPRS/dataset/folder/"
BATCH_SIZE = 10 # Number of samples in a mini-batch

LABELS = ['Martian Soil', 'Sands', 'Gravel', 'Bedrock', 'Rocks',
                   'Tracks', 'Shadows', 'Unknown', 'Background']
N_CLASSES = len(LABELS) # Number of classes
WEIGHTS = torch.ones(N_CLASSES) # Weights for class balancing
CACHE = True # Store the dataset in-memory

MAIN_FOLDER_V = FOLDER + 'MER/'
DATA_FOLDER_V = MAIN_FOLDER_V + 'images/{}.jpg'
LABEL_FOLDER_V = MAIN_FOLDER_V + 'label_RGB/{}.png'
Depth_FOLDER_V = MAIN_FOLDER_V + 'depth/{}.png'

MAIN_FOLDER_P = FOLDER + 'MSL/'
DATA_FOLDER_P = MAIN_FOLDER_P + 'images/{}.jpg'
LABEL_FOLDER_P = MAIN_FOLDER_P + 'label_RGB/{}.png'
Depth_FOLDER_P = MAIN_FOLDER_P + 'depth_512/{}.png'
# net = ResUnetPlusPlus(3).cuda()

model = ViT_seg(num_classes=N_CLASSES)
params = 0
for name, param in model.named_parameters():
    params += param.nelement()
print(params)
# saved_state_dict = torch.load('2_Advent/pretrained/DeepLab_resnet_pretrained_imagenet.pth')
# new_params = model.state_dict().copy()
# for i in saved_state_dict:
#     i_parts = i.split('.')
#     if not i_parts[1] == 'layer5':
#         new_params['.'.join(i_parts[1:])] = saved_state_dict[i]
# model.load_state_dict(new_params)
model.train()
model = model.cuda()
cudnn.benchmark = True
cudnn.enabled = True
d_aux = transDiscri(num_classes=N_CLASSES)
d_aux.train()
d_aux.cuda()

d_aux_depth = transDiscri(num_classes=N_CLASSES)
d_aux_depth.train()
d_aux_depth.cuda()


# seg maps, i.e. output, level
d_main = transDiscri(num_classes=N_CLASSES)
d_main.train()
d_main.cuda()


d_main_depth = transDiscri(num_classes=N_CLASSES)
d_main_depth.train()
d_main_depth.cuda()


train_ids_V = ['97', '541', '799', '214', '411', '80', '828', '723', '276', '59', '192', '682', '144', '187', '1014', '493', '856', '767', '21', '118', '922', '343', '639', '482', '1047', '488', '44', '667', '956', '301', '841', '954', '973', '243', '933', '516', '6', '983', '957', '317', '564', '52', '260', '917', '281', '708', '15', '314', '49', '10', '3', '333', '556', '181', '868', '979', '297', '390', '379', '668', '215', '348', '980', '560', '637', '205', '506', '827', '575', '222', '156', '73', '762', '234', '94', '511', '1061', '790', '653', '418', '734', '1057', '1000', '997', '32', '113', '478', '513', '35', '357', '311', '571', '290', '38', '91', '127', '642', '140', '308', '424', '1005', '608', '71', '248', '861', '789', '659', '405', '823', '322', '504', '324', '274', '1027', '758', '498', '940', '927', '657', '686', '361', '434', '512', '329', '855', '988', '974', '616', '849', '420', '626', '57', '798', '874', '813', '78', '851', '860', '786', '401', '909', '660', '446', '882', '37', '89', '341', '259', '863', '55', '946', '510', '802', '992', '783', '302', '809', '953', '452', '174', '818', '754', '412', '255', '67', '271', '1020', '136', '1017', '402', '845', '985', '699', '633', '538', '518', '662', '392', '1040', '275', '272', '1030', '386', '47', '286', '338', '898', '651', '867', '738', '473', '817', '565', '948', '797', '519', '720', '484', '416', '431', '238', '681', '495', '617', '1029', '393', '780', '443', '232', '731', '649', '471', '590', '912', '413', '186', '347', '670', '382', '553', '46', '489', '562', '573', '650', '310', '335', '914', '692', '88', '155', '395', '710', '396', '148', '858', '899', '496', '56', '179', '500', '132', '458', '929', '1035', '342', '977', '464', '945', '586', '437', '171', '166', '665', '733', '201', '92', '330', '1032', '964', '450', '749', '105', '200', '724', '926', '570', '162', '117', '644', '871', '862', '782', '551', '240', '346', '569', '157', '43', '947', '903', '842', '456', '994', '269', '277', '82', '19', '403', '764', '803', '890', '441', '319', '839', '937', '447', '384', '857', '252', '795', '924', '408', '244', '1023', '804', '25', '529', '930', '251', '385', '208', '656', '60', '578', '744', '943', '902', '623', '364', '881', '647', '397', '843', '1011', '289', '776', '679', '634', '508', '76', '426', '884', '889', '430', '1044', '931', '467', '438', '597', '528', '703', '209', '415', '793', '696', '376', '87', '535', '195', '183', '701', '247', '552', '661', '487', '756', '378', '840', '777', '479', '962', '887', '29', '894', '698', '1049', '66', '866', '111', '404', '836', '770', '374', '428', '521', '919', '64', '913', '368', '747', '417', '20', '202', '101', '920', '287', '574', '503', '904', '161', '340', '517', '151', '172', '705', '605', '380', '1012', '635', '550', '427', '106', '65', '477', '99', '736', '601', '944', '1062', '14', '800', '167', '69', '228', '28', '154', '967', '714', '230', '349', '995', '779', '976', '1033', '830', '305', '713', '694', '485', '26', '79', '1064', '455', '175', '459', '12', '907', '932', '949', '939', '999', '965', '846', '918', '619', '1016', '109', '986', '676', '7', '439', '629', '549', '120', '1015', '588', '4', '263', '928', '40', '462', '213', '987', '716', '717', '750', '941', '249', '191', '98', '134', '451', '522', '824', '559', '545', '359', '515', '751', '350', '466', '354', '896', '391', '826', '915', '253', '775', '577', '470', '146', '328', '475', '607', '18', '704', '429', '50', '356', '8', '264', '270', '128', '643', '838', '759', '675', '677', '112', '102', '576', '216', '822', '285', '1019', '715', '45', '700', '1038', '706', '951', '84', '158', '688', '611', '1018', '453', '461', '176', '534', '612', '959', '190', '671', '180', '406', '30', '916', '225', '143', '725', '351', '523', '810', '625', '1039', '579', '952', '95', '572', '492', '278', '399', '972', '695', '905', '1009', '732', '663', '1059', '398', '566', '114', '193', '632', '1022', '358', '853', '624', '177', '142', '400', '198', '739', '224', '875', '494', '773', '1042', '100', '895', '1031', '292', '761', '563', '362', '606', '107', '923', '938', '652', '313', '1056', '367', '829', '693', '546', '1055', '457', '315', '850', '958', '707', '75', '658', '23', '321', '886', '115', '524', '123', '812', '164', '296', '587', '360', '1006', '906', '282', '557', '567', '687', '440', '435', '39', '295', '77', '375', '885', '966', '825', '942', '256', '526', '31', '254', '542', '1010', '620', '325', '609', '145', '520', '454', '741', '219', '242', '1024', '745', '711', '170', '1046', '62', '771', '769', '421', '502', '722', '284', '785', '1041', '788', '514', '110', '891', '525', '51', '730', '61', '469', '581', '149', '993', '684', '283', '702', '1054', '13', '265', '352', '806', '262', '409', '476', '1052', '472', '410', '491', '600', '345', '835', '615', '116', '1001', '159', '327', '1028', '463', '674', '307', '935', '757', '561', '864', '879', '768', '547', '139', '536', '796', '445', '936', '280', '169', '1021', '755', '1037', '655', '631', '196', '48', '366', '532', '33', '474', '678', '568', '58', '628', '595', '594', '1063', '372', '618', '934', '765', '221', '486', '554', '1036', '383', '74', '859', '805', '968', '592', '468', '963', '226', '288', '847', '888', '497', '212', '1034', '369', '645', '320', '630', '1060', '267', '373', '990', '1007', '540', '204', '961', '239', '318', '465', '203', '583', '241', '527', '811', '1003', '690', '304', '950', '709', '246', '419', '1045', '407', '673', '543', '729', '1058', '168', '72', '86', '691', '669', '807', '303', '989', '442', '603', '235', '217', '792', '54', '854', '848', '236', '90', '627', '337', '740', '544', '900', '820', '666', '499', '1025', '103', '165', '133', '880', '955', '231', '1026', '150', '530', '1050', '153', '548', '189', '332', '689', '147', '844', '27', '96', '306', '11', '873', '815', '293', '130', '794', '273', '268', '614', '584', '365', '432', '648', '727', '897']

test_ids_V = ['816', '539', '808', '83', '448', '585', '121', '654', '883', '131', '300', '245', '68', '752', '558', '124', '982', '433', '599', '1004', '978', '505', '911', '821', '589', '194', '760', '748', '613', '41', '119', '16', '394', '279', '2', '34', '975', '220', '227', '126', '481', '257', '182', '423', '81', '910', '17', '258', '680', '377', '233', '93', '533', '876', '726', '178', '781', '125', '998', '636', '555', '344', '184', '326', '388', '291', '323', '331', '1053', '490', '218', '298', '602', '22', '893', '970', '721', '316', '509', '878', '664', '211', '971', '137', '24', '70', '460', '638', '865', '610', '449', '353', '371', '444', '129', '483', '537', '791', '580', '737', '870', '901', '370', '261', '309', '138', '984', '593', '640', '108', '683', '672', '299', '778', '339', '104', '355', '834', '122', '160', '604', '42', '819', '981', '414', '250', '742', '63', '728', '197', '294', '531', '1048', '996', '334', '223', '207', '869', '960', '774', '1013', '969', '831', '746', '772', '582', '507', '237', '814', '921', '833', '199', '425', '1002', '363', '141', '5', '719', '685', '1043', '163', '925', '784', '712', '718', '185', '210', '801', '787', '480', '36', '991', '436', '892', '877', '389', '173', '641', '1008', '501', '837', '9', '135', '85', '598', '908', '763', '1051', '591', '312', '188', '206', '336', '697', '1', '622', '152', '381', '422', '743', '852', '266', '646', '387', '735', '872', '53', '832', '596', '766', '229', '753', '621']

train_ids_P = ['1808', '3339', '2937', '76', '3134', '2474', '2286', '3564', '1185', '470', '991', '598', '1611', '796', '1467', '1161', '1559', '2137', '1238', '2044', '2257', '1052', '1844', '2666', '891', '2680', '371', '319', '1247', '819', '3430', '1879', '3885', '2075', '471', '1995', '3470', '3785', '666', '2059', '3681', '690', '3896', '2904', '1272', '1951', '647', '2640', '3606', '1070', '3841', '785', '401', '2397', '1667', '2032', '1671', '3462', '716', '3926', '3384', '2033', '2079', '692', '3187', '3173', '2203', '3348', '1840', '1230', '807', '3864', '128', '118', '2394', '3333', '2987', '3264', '3419', '381', '2057', '546', '2451', '9', '3352', '2766', '1668', '2362', '782', '1976', '445', '2368', '651', '1457', '3104', '3615', '2864', '1001', '87', '2824', '1357', '2046', '2969', '2757', '984', '435', '2958', '3765', '413', '544', '1593', '1377', '1217', '36', '3232', '2252', '46', '2001', '3619', '551', '3790', '1381', '1331', '839', '2225', '2388', '1653', '465', '2705', '242', '3344', '3658', '2098', '277', '1678', '1900', '1578', '1931', '2148', '2731', '3694', '355', '995', '74', '2029', '659', '3642', '784', '1810', '685', '3195', '34', '473', '1501', '3731', '1009', '107', '3177', '815', '1669', '2839', '69', '1735', '1300', '2851', '1474', '2845', '2996', '1469', '1540', '2237', '1059', '2875', '2372', '1291', '2595', '333', '894', '843', '3882', '3570', '3370', '3018', '3277', '3880', '3809', '3577', '2543', '873', '3636', '639', '3712', '2405', '3623', '1450', '1622', '1590', '1619', '3800', '626', '1164', '2395', '2817', '3071', '3750', '2403', '3354', '3328', '3723', '1510', '2376', '882', '789', '2191', '862', '357', '2794', '2557', '1534', '1920', '1094', '3112', '1899', '1695', '3289', '3387', '3373', '58', '3556', '2526', '1732', '3604', '3514', '787', '887', '2392', '2809', '32', '2306', '2676', '1466', '497', '2012', '1212', '2402', '1703', '156', '240', '2024', '1047', '1953', '2591', '416', '540', '3907', '2107', '2486', '112', '2866', '972', '1729', '2847', '1335', '1837', '2499', '198', '3483', '686', '3295', '3286', '3545', '2370', '3575', '2844', '3526', '3887', '1720', '917', '491', '1332', '362', '1723', '3740', '662', '1309', '914', '2452', '1587', '1061', '2545', '2126', '2903', '844', '1828', '3690', '2963', '2294', '3818', '2590', '3795', '2978', '1406', '2988', '207', '2481', '1718', '3244', '2840', '3911', '2410', '3416', '3233', '3253', '1233', '3782', '104', '1420', '3863', '3126', '227', '1362', '2398', '1612', '970', '3341', '2629', '1437', '3850', '2171', '2547', '3817', '1866', '1602', '3466', '3006', '3114', '2783', '3490', '1051', '3618', '3599', '1833', '1193', '2058', '212', '3155', '2208', '3924', '1039', '3250', '3223', '2482', '605', '506', '495', '1113', '3844', '3008', '1167', '133', '3699', '2994', '2764', '1298', '3320', '3162', '3284', '1266', '768', '3587', '2520', '464', '2119', '2549', '2831', '2511', '2552', '910', '577', '1599', '3761', '951', '3304', '216', '3395', '1781', '3563', '2399', '1500', '3444', '3835', '3217', '618', '41', '1404', '2760', '523', '2945', '2187', '1853', '719', '2928', '1917', '2356', '3210', '572', '1584', '1924', '2353', '3914', '3163', '3855', '2186', '1124', '3524', '163', '288', '3808', '763', '1832', '405', '2453', '2539', '2350', '3772', '710', '3744', '70', '966', '2992', '2527', '1827', '459', '2078', '3756', '3382', '117', '1944', '2487', '3239', '2299', '2881', '2504', '1663', '57', '462', '1958', '3862', '574', '3100', '3079', '1486', '1234', '1969', '2227', '713', '2799', '1942', '73', '3170', '1092', '630', '1521', '2470', '3739', '3487', '667', '1089', '3403', '3206', '1243', '1861', '3491', '3215', '1248', '457', '846', '315', '896', '565', '834', '2934', '2184', '3238', '90', '3422', '1465', '3597', '2944', '2784', '2677', '3351', '3482', '2716', '852', '1597', '634', '996', '911', '44', '1109', '2345', '1473', '2026', '2758', '3710', '353', '2805', '1897', '2280', '3548', '3012', '3572', '1141', '2751', '2691', '1042', '2572', '726', '1525', '2155', '1987', '3230', '564', '2142', '1818', '1455', '28', '3121', '1551', '340', '3485', '3102', '786', '929', '1296', '2933', '1829', '2228', '477', '2668', '2412', '251', '2271', '1783', '2325', '3840', '391', '225', '562', '2207', '424', '1570', '1057', '1758', '3433', '1072', '691', '239', '2524', '2870', '3820', '813', '1960', '1277', '3332', '3531', '3879', '7', '802', '1199', '1542', '2411', '3431', '556', '1679', '3150', '358', '1709', '545', '2732', '2066', '2478', '1759', '1520', '1452', '733', '3579', '2508', '2068', '3375', '500', '2320', '498', '3920', '3675', '258', '3442', '2648', '3705', '968', '1696', '3735', '868', '2573', '990', '155', '973', '1173', '928', '3488', '232', '1342', '3627', '1418', '3551', '91', '794', '957', '2400', '2307', '3094', '3176', '2925', '3894', '3182', '3236', '3734', '2982', '2505', '55', '1926', '2217', '3429', '2815', '889', '2708', '1411', '3657', '1386', '454', '3644', '1889', '1262', '1849', '2949', '1766', '2438', '2429', '2852', '867', '1276', '1623', '2173', '3139', '1497', '748', '217', '2021', '2176', '3448', '3828', '2017', '2531', '1195', '2553', '3321', '519', '1356', '3335', '1425', '442', '3581', '1147', '1906', '3475', '1761', '2386', '3081', '797', '2437', '3127', '3439', '4', '1318', '2210', '663', '3706', '971', '2240', '969', '3478', '976', '3330', '2006', '2632', '1055', '3293', '2923', '1892', '3753', '1267', '3427', '3073', '2221', '3562', '2516', '1740', '1314', '2694', '1860', '2940', '302', '3411', '1274', '816', '1349', '2491', '515', '1196', '832', '2396', '2005', '1691', '1442', '913', '2382', '1835', '1820', '25', '1068', '1129', '1095', '1940', '3229', '113', '905', '3923', '3567', '1526', '3003', '1007', '3391', '176', '1422', '3186', '641', '466', '1365', '2765', '655', '2448', '2494', '1368', '2709', '3130', '3160', '2529', '2297', '1915', '3398', '1727', '3366', '2369', '226', '3876', '1481', '3687', '115', '2920', '1564', '3501', '2530', '171', '622', '2330', '3917', '2011', '3371', '3085', '2617', '2292', '3198', '823', '2061', '1847', '520', '1045', '1925', '1480', '2102', '3791', '134', '276', '415', '2426', '883', '2197', '213', '1998', '180', '1643', '3202', '2279', '2954', '941', '407', '86', '1389', '1575', '105', '1801', '1908', '931', '3881', '3001', '2118', '2707', '1056', '3039', '1385', '960', '2464', '2220', '1432', '1795', '2555', '2174', '908', '3290', '698', '3707', '3314', '946', '249', '1568', '2305', '3616', '581', '752', '1676', '2083', '2756', '3067', '3505', '2561', '2514', '2359', '2379', '573', '3742', '2140', '601', '3196', '1203', '1549', '411', '301', '2144', '2377', '3510', '3436', '922', '2999', '2571', '75', '3385', '162', '2599', '1518', '224', '2583', '3900', '3028', '2194', '2971', '2268', '493', '2873', '559', '2022', '2596', '1038', '1964', '2050', '1651', '1704', '496', '2211', '1337', '2686', '798', '649', '3088', '2586', '1242', '743', '765', '3737', '2', '824', '2371', '3708', '1682', '1708', '1198', '51', '1037', '3738', '3122', '3780', '2218', '1980', '2974', '265', '2101', '3779', '508', '2201', '3273', '1965', '1446', '1482', '708', '3004', '2922', '161', '2106', '1680', '1444', '1918', '3481', '774', '2479', '1690', '915', '1585', '1012', '275', '1950', '3220', '1582', '290', '1322', '2828', '2685', '3649', '3271', '2902', '1163', '1863', '1685', '2769', '2117', '3285', '778', '1747', '580', '1396', '2077', '318', '1083', '2256', '576', '1175', '1142', '2850', '681', '1380', '157', '632', '3656', '1062', '2827', '1227', '522', '3242', '1428', '108', '2245', '50', '3786', '3757', '3110', '1307', '898', '1996', '729', '80', '1636', '2970', '2739', '3626', '2298', '3892', '3007', '278', '1429', '1633', '2989', '1048', '2409', '2993', '1105', '1138', '2490', '2341', '1815', '29', '2070', '2931', '3910', '335', '2981', '942', '3718', '332', '298', '3883', '1724', '2521', '2935', '1846', '2683', '2183', '1376', '1870', '1306', '1215', '1348', '646', '43', '2650', '3528', '673', '2430', '1186', '769', '2324', '3267', '1498', '2497', '3172', '2807', '3306', '1910', '1649', '3541', '3717', '186', '3302', '1281', '958', '2180', '2152', '2475', '285', '3822', '2009', '3805', '3129', '3325', '2621', '2178', '1806', '1981', '3124', '2746', '2074', '2869', '2219', '3661', '3056', '3063', '2859', '3598', '1355', '1577', '711', '1076', '3168', '3251', '3747', '1245', '314', '1148', '2138', '262', '1289', '1326', '1312', '8', '3671', '1675', '2340', '3888', '3133', '2601', '2613', '12', '116', '3026', '856', '236', '2907', '2108', '1745', '2027', '2175', '3317', '1854', '3506', '2160', '2788', '3702', '2342', '3346', '1204', '3899', '3312', '1067', '246', '2085', '141', '3278', '1855', '2327', '2449', '841', '1662', '402', '2417', '2602', '1990', '1514', '2485', '1625', '1640', '2916', '530', '2800', '2086', '811', '1080', '472', '22', '2718', '208', '3854', '521', '408', '1229', '1792', '433', '1660', '1569', '3726', '3441', '1174', '2953', '2258', '1069', '2290', '2422', '1579', '3639', '2753', '3064', '3632', '126', '2458', '1383', '2779', '2980', '3525', '1812', '2134', '2592', '2168', '2373', '3477', '422', '1485', '934', '195', '244', '2270', '1064', '478', '2143', '1478', '1851', '853', '2962', '1934', '793', '1407', '1462', '963', '3715', '3693', '3049', '1237', '3418', '3105', '606', '2986', '1873', '3494', '3248', '3830', '3136', '2308', '1366', '3334', '427', '2887', '587', '3476', '2579', '1401', '3484', '1468', '2251', '1382', '1279', '2042', '1115', '2056', '1395', '0', '1293', '1015', '428', '1901', '2880', '3426', '1125', '2879', '3324', '1013', '2706', '1086', '1771', '1461', '2740', '3638', '3612', '1555', '367', '3059', '640', '1604', '370', '2642', '732', '1628', '2701', '406', '2623', '384', '369', '2065', '100', '201', '1214', '3774', '2835', '705', '390', '2796', '1341', '1821', '1063', '1336', '1100', '644', '1187', '2365', '463', '2901', '3508', '310', '1923', '746', '2849', '1916', '1216', '142', '3515', '1102', '2927', '907', '2471', '184', '2104', '199', '1135', '1085', '1121', '1903', '3062', '3611', '1553', '1028', '187', '3700', '2289', '1756', '3898', '1538', '1875', '65', '2717', '2469', '2115', '88', '3613', '3358', '2512', '2559', '2593', '1804', '2939', '1952', '1171', '2759', '247', '940', '26', '1228', '2871', '2146', '2282', '821', '1000', '2966', '2124', '1600', '1155', '2303', '1657', '527', '2128', '1449', '1363', '3512', '3336', '3268', '742', '193', '374', '1156', '1516', '3580', '2250', '553', '3329', '1088', '3420', '3647', '956', '3719', '2312', '1576', '829', '166', '814', '283', '537', '1202', '3151', '2619', '3369', '3770', '2995', '1191', '2811', '2419', '284', '1673', '2503', '2109', '919', '1588', '1447', '1024', '2546', '2698', '1887', '1936', '2826', '2692', '3394', '2674', '2704', '2736', '3468', '2205', '1090', '1561', '2076', '1779', '1409', '2424', '2192', '67', '1858', '709', '2500', '2338', '1572', '3153', '1403', '2013', '2375', '3792', '37', '2460', '205', '596', '2797', '610', '3603', '2582', '3144', '507', '3680', '1016', '738', '174', '1816', '1477', '1705', '3023', '2885', '1483', '3140', '2346', '2955', '2568', '628', '1654', '3035', '30', '3549', '3074', '783', '485', '845', '2223', '665', '3532', '3543', '3812', '1443', '2332', '3368', '2606', '2518', '2391', '1912', '2266', '1458', '2195', '1400', '3674', '1714', '1616', '3486', '3727', '861', '1181', '2627', '2354', '2233', '3460', '3561', '3497', '3843', '3825', '2151', '1077', '2030', '1354', '3408', '3424', '3594', '3311', '1972', '835', '3090', '1424', '2991', '3721', '706', '2374', '1563', '127', '3025', '173', '499', '3044', '3040', '2461', '3566', '1197', '1226', '2959', '45', '2938', '3764', '880', '1686', '3838', '3748', '2036', '3406', '1297', '101', '5', '2947', '3146', '2926', '53', '460', '1074', '3208', '2558', '13', '1566', '2421', '718', '3038', '1301', '182', '3437', '3467', '2492', '1413', '2111', '1697', '2882', '2100', '3307', '3005', '3569', '2830', '1323', '1993', '1798', '1374', '2960', '1391', '2878', '376', '2162', '2408', '3209', '222', '2950', '488', '3340', '2288', '1699', '221', '703', '1303', '3517', '1084', '3509', '2496', '2833', '2159', '2728', '1140', '2696', '181', '764', '2906', '3280', '3029', '509', '2695', '771', '2587', '3536', '248', '1002', '3858', '3045', '1743', '3179', '2900', '368', '83', '2313', '398', '997', '1097', '1260', '3866', '2094', '831', '3803', '1264', '2790', '85', '3019', '2979', '2930', '773', '2625', '761', '3184', '452', '1043', '3451', '2735', '2905', '82', '3492', '1165', '2105', '2080', '2667', '3445', '1358', '482', '1823', '210', '3725', '254', '3276', '3793', '492', '614', '513', '3823', '2067', '3355', '767', '3310', '1776', '1605', '3089', '589', '875', '2455', '1157', '830', '1614', '347', '854', '3274', '3754', '526', '2275', '1240', '3376', '3203', '2418', '1359', '1130', '1390', '3053', '687', '1209', '2390', '1725', '3032', '1589', '674', '2729', '1375', '1914', '617', '1158', '409', '772', '2267', '607', '3901', '2967', '3537', '179', '327', '3807', '1475', '3834', '3299', '3534', '1805', '714', '2158', '1451', '1504', '280', '1845', '2209', '1949', '2015', '2688', '2897', '2226', '1241', '2244', '3365', '2678', '3849', '693', '736', '3557', '3746', '2793', '172', '2721', '3546', '3322', '2541', '672', '541', '547', '3024', '2712', '1692', '1610', '591', '3648', '2493', '84', '1728', '1128', '268', '1239', '1983', '2679', '1734', '953', '2484', '2643', '3106', '3030', '0', '192', '3851', '567', '3353', '149', '2703', '1154', '3853', '1784', '721', '2689', '3017', '1394', '3664', '3086', '3275', '469', '2509', '871', '542', '3589', '1066', '2378', '1954', '3228', '49', '1453', '1974', '1586', '1149', '2089', '1541', '808', '1770', '2480', '1213', '2051', '209', '920', '937', '1273', '525', '3640', '675', '1737', '1711', '2054', '817', '274', '2263', '1294', '2575', '364', '200', '822', '1825', '3578', '3732', '1885', '3733', '954', '1852', '63', '3192', '3037', '3455', '2028', '2768', '592', '1626', '1134', '125', '810', '2135', '3078', '420', '3857', '234', '95', '2120', '1107', '2968', '2630', '3204', '272', '518', '2921', '2291', '2762', '927', '2099', '3716', '2964', '260', '441', '1319', '1232', '3775', '3116', '671', '39', '3760', '923', '2773', '1539', '170', '1320', '3138', '92', '3327', '745', '474', '448', '3918', '1284', '3722', '2087', '467', '2141', '93', '2336', '204', '3291', '2589', '654', '1997', '1884', '1419', '3922', '130', '3363', '3404', '2466', '3262', '253', '2877', '552', '895', '387', '158', '1988', '1933', '3868', '431', '243', '1581', '571', '2523', '609', '3867', '1317', '3628', '2690', '3254', '2614', '2899', '3390', '795', '1445', '3553', '2738', '3193', '395', '3703', '1945', '1448', '1398', '153', '1765', '2936', '3380', '1921', '99', '1746', '528', '3861', '3113', '14', '1670', '3142', '1975', '1598', '2476', '324', '47', '2311', '2198', '3600', '1340', '2890', '3413', '1325', '183', '2273', '1427', '3125', '1938', '2091', '1977', '1613', '1788', '2624', '1880', '2467', '1787', '1439', '3158', '2609', '3374', '2262', '3166', '3098', '2483', '1346', '2447', '252', '1932', '1813', '961', '2616', '144', '3305', '3801', '2874', '3042', '1472', '2285', '2886', '524', '3221', '2489', '1430', '3824', '2909', '3435', '1222', '661', '3091', '3590', '1127', '3768', '2733', '1223', '2040', '2785', '3540', '382', '3447', '1194', '1716', '2618', '1524', '2662', '2673', '2533', '2654', '1110', '3905', '1502', '933', '2537', '2752', '3602', '3342', '3592', '744', '380', '2943', '2581', '2645', '3269', '1859', '2891', '3620', '255', '10', '2649', '372', '3296', '1415', '3655', '776', '3588', '938', '1992', '2334', '1984', '317', '3709', '2687', '3811', '3256', '2326', '245', '1591', '2941', '1139', '642', '235', '3582', '2798', '110', '1819', '3565', '1036', '2352', '855', '1822', '3069', '2234', '2427', '3678', '3697', '177', '3169', '739', '566', '2193', '1634', '3440', '1176', '899', '3847', '1350', '1762', '229', '3781', '620', '1713', '3653', '3908', '3128', '2214', '3513', '27', '625', '548', '1802', '1103', '3852', '312', '2331', '876', '2780', '3769', '1231', '3319', '2772', '3415', '3662', '3240', '2684', '3033', '3605', '1522', '2633', '2156', '1719', '858', '3428', '549', '2360', '2149', '286', '2548', '2564', '1180', '3595', '2147', '1178', '160', '1683', '2316', '2445', '3672', '2781', '338', '3175', '2737', '3832', '1800', '1650', '1219', '885', '2884', '2550', '223', '955', '3118', '801', '930', '2578', '3884', '2064', '233', '3796', '2876', '1087', '676', '2150', '3925', '2383', '2584', '289', '3414', '514', '3255', '1046', '2598', '2358', '2439', '1894', '2574', '2889', '1677', '468', '701', '2577', '2328', '282', '1032', '2653', '2347', '313', '2246', '594', '2253', '3788', '379', '992', '1862', '842', '96', '2276', '345', '1131', '159', '196', '3', '1183', '1883', '1372', '1489', '1160', '1919', '1991', '1631', '3323', '2693', '150', '1299', '399', '3066', '780', '3417', '3097', '2317', '1895', '2020', '2620', '635', '1532', '760', '21', '510', '443', '2323', '561', '3080', '2034', '2812', '1476', '1601', '2343', '1207', '998', '1970', '3389', '3875', '2946', '2918', '3212', '1499', '2754', '3392', '3815', '2172', '1608', '3751', '2647', '2742', '1647', '2242', '3054', '3596', '16', '2750', '2832', '325', '804', '857', '2130', '2658', '1179', '623', '2465', '2646', '3410', '2103', '2635', '3432', '1550', '1645', '3684', '1632', '3076', '3225', '2381', '645', '2284', '1512', '2116', '3816', '1545', '479', '2872', '3452', '1421', '98', '1702', '1741', '3692', '989', '1665', '583', '15', '2047', '2838', '3645', '1621', '1968', '2196', '203', '3813', '2763', '2651', '512', '267', '2631', '2472', '925', '2002', '1506', '584', '1313', '1423', '3711', '3135', '751', '1715', '1136', '3292', '348', '900', '2722', '2092', '269', '453', '3826', '1168', '1689', '17', '3472', '2446', '2977', '1269', '3474', '2322', '1347', '2948', '1893', '3383', '1882', '2122', '1236', '2259', '1275', '3259', '61', '902', '366', '3568', '1744', '2052', '2975', '1967', '2133', '3147', '3200', '2215', '351', '3607', '434', '3111', '2911', '3298', '1624', '2786', '631', '2264', '123', '909', '820', '3621', '2495', '2952', '1867', '326', '3837', '1658', '323', '870', '2132', '731', '2477', '1495', '2912', '2741', '539', '3624', '481', '3667', '1571', '568', '124', '1830', '2727', '296', '2700', '1864', '847', '1108', '403', '197', '143', '3839', '590', '2423', '1841', '3154', '425', '1144', '932', '449', '3504', '1642', '1902', '3878', '3821', '1772', '3877', '421', '444', '627', '3810', '903', '1896', '3784', '3034', '3741', '1433', '3084', '912', '3682', '145', '2540', '2745', '3461', '1251', '2062', '3164', '135', '3499', '1700', '3201', '322', '1143', '766', '218', '24', '3058', '3519', '1905', '2053', '1655', '2823', '138', '2380', '1122', '1775', '2997', '273', '3301', '2269', '1471', '3450', '952', '2125', '3921', '2314', '3503', '386', '986', '250', '535', '455', '3109', '489', '1693', '1957', '359', '266', '981', '3010', '3362', '297', '836', '1629', '892', '2924', '3405', '1706', '3119', '3585', '994', '977', '1249', '2170', '637', '1494', '682', '2063', '2401', '935', '62', '1956', '1898', '1911', '1434', '2114', '38', '6', '3171', '3601', '2413', '119', '825', '2389', '3634', '1392', '1352', '1843', '1722', '1211', '569', '1344', '2319', '1842', '3698', '2235', '1947', '2749', '1890', '3367', '1637', '554', '3871', '1492', '3869', '3660', '1797', '352', '3889', '1058', '2260', '730', '2888', '501', '349', '1907', '2025', '3763', '1091', '2293', '2121', '1218', '3673', '3068', '1752', '679', '2096', '2669', '2200', '3498', '2123', '167', '697', '1982', '643', '792', '1172', '1159', '1118', '2321', '734', '3197', '64', '2585', '2248', '350', '1712', '516', '2778', '1014', '3181', '563', '263', '2502', '3827', '2841', '517', '271', '3891', '256', '2351', '3533', '2000', '165', '175', '1119', '1874', '555', '2414', '2761', '188', '3065', '2892', '2443', '363', '486', '1287', '1470', '3050', '2432', '1558', '1250', '361', '1878', '3075', '1011', '1971', '2428', '1496', '2570', '3471', '3798', '1329', '2942', '480', '3630', '1946', '20', '1208', '1304', '1774', '3593', '1554', '1071', '270', '3583', '1201', '3048', '2088', '3584', '1799', '3668', '2008', '211', '3539', '1101', '2153', '3159', '3257', '534', '1305', '1393', '2910', '3870', '3326', '2792', '2808', '2843', '3211', '1836', '2803', '2406', '2965', '2747', '949', '2567', '3895', '2357', '3677', '3586', '1479', '2615', '303', '3246', '1282', '306', '3258', '3396', '1146', '1189', '2917', '781', '688', '888', '2608', '1177', '2387', '1994', '1327', '3625', '3629', '1872', '3743', '3669', '136', '881', '164', '3149', '660', '121', '3183', '2597', '2825', '3789', '1523', '980', '2283', '2985', '31', '511', '3689', '1254', '1528', '1803', '613', '389', '1519', '579', '1592', '2671', '947', '936', '111', '1871', '3633', '3713', '638', '2222', '1701', '2563', '503', '1098', '1574', '1188', '2404', '2560', '1490', '1288', '2182', '2638', '2636', '1929', '169', '1726', '2241', '2855', '1257', '378', '1785', '1487', '3479', '3237', '1328', '2860', '777', '1793', '2842', '1431', '1778', '3650', '300', '1184', '939', '689', '1040', '3720', '874', '1913', '557', '1767', '3167', '40', '219', '3434', '3157', '3676', '1620', '1044', '1162', '1790', '2956', '1717', '3313', '2167', '728', '337', '206', '1454', '3666', '72', '1661', '2010', '3399', '1580', '2542', '504', '826', '1459', '1638', '877', '3009', '2224', '2004', '2038', '3345', '2261', '3361', '3283', '3520', '2804', '139', '1334', '3123', '1567', '2848', '866', '3141', '921', '1769', '2714', '3559', '2711', '2131', '94', '3511', '1543', '1834', '1065', '3665', '3145', '2301', '2726', '2169', '3691', '1364', '893', '342', '3787', '2789', '1986', '1807', '77', '806', '2611', '3143', '2145', '2538', '1259', '3131', '1505', '437', '185', '1560', '3903', '1073', '2661', '550', '385', '849', '3020', '3777', '241', '1210', '1082', '375', '331', '109', '305', '1008', '2748', '3745', '1672', '1137', '1417', '3226', '1111', '3464', '770', '850', '3554', '3338', '2652', '2681', '3685', '2863', '2055', '678', '2628', '2819', '2060', '3152', '1730', '2895', '2580', '1170', '1145', '944', '3446', '2637', '3057', '1607', '1962', '1739', '1220', '886', '3783', '818', '2816', '582', '450', '1791', '3051', '320', '33', '1609', '456', '3759', '2255', '1441', '536', '3646', '3550', '1435', '2488', '1414', '3797', '19', '2459', '1738', '2454', '803', '1221', '529', '3874', '2697', '724', '1292', '2544', '2278', '1378', '2610', '3773', '1641', '2603', '3728', '2858', '2188', '959', '3132', '2961', '2990', '3659', '3552', '1315', '2385', '1488', '2519', '2854', '2384', '964', '1694', '2296', '1261', '2665', '2771', '838', '3117', '1438', '341', '1868', '543', '1750', '2612', '2339', '3560', '3107', '1405', '3103', '293', '3249', '3402', '901', '237', '2110', '3245', '3538', '3776', '3165', '1099', '2247', '2929', '3493', '2277', '648', '3495', '1786', '1876', '3571', '2363', '1200', '725', '1010', '238', '758', '756', '360', '3148', '1093', '2232', '533', '2675', '2082', '3767', '2457', '3919', '3652', '1888', '664', '585', '396', '2420', '430', '412', '999', '1049', '2349', '2165', '383', '3115', '755', '356', '1399', '3055', '1531', '2715', '2315', '2801', '404', '3096', '1537', '2657', '1635', '2069', '3859', '2660', '2626', '194', '3829', '2818', '1753', '3281', '3794', '906', '1794', '2348', '476', '2023', '3480', '1026', '1768', '1302', '2295', '624', '3360', '3046', '2867', '3755', '2813', '3300', '1412', '259', '439', '3261', '308', '1192', '1029', '190', '2309', '1166', '106', '2462', '1150', '330', '717', '257', '154', '1290', '97', '1573', '683', '1939', '2837', '397', '1535', '1966', '2515', '3207', '3695', '1959', '1339', '230', '2436', '1789', '1646', '2154', '1742', '775', '2433', '3574', '2699', '2136', '1627', '1333', '3530', '3381', '1371', '1869', '3191', '670', '1224', '3915', '560', '393', '3836', '3247', '1517', '2894', '414', '2239', '2777', '309', '2249', '2525', '2972', '3337', '2035', '365', '483', '1379', '988', '1961', '532', '2393', '2213', '2594', '1493', '2565', '695', '586', '1764', '2041', '60', '388']

test_ids_P = ['840', '863', '1639', '2072', '2562', '1416', '2113', '502', '2003', '3916', '3842', '343', '3778', '754', '950', '2506', '904', '2802', '791', '3617', '668', '3174', '1271', '2725', '3260', '2199', '2896', '1151', '2622', '328', '749', '1311', '2084', '1022', '1263', '2998', '1078', '3522', '2734', '346', '1838', '3397', '3356', '114', '2157', '3423', '2501', '1891', '148', '1316', '1106', '3591', '3219', '1270', '578', '3819', '2127', '2724', '3473', '1529', '3015', '1491', '3315', '3893', '438', '2302', '2774', '505', '1033', '864', '3093', '2806', '704', '975', '316', '3265', '1773', '68', '400', '3060', '2664', '2254', '3886', '2189', '2431', '611', '2163', '1360', '735', '974', '3608', '3099', '3120', '1817', '79', '494', '890', '3654', '2272', '334', '189', '3331', '151', '2919', '2498', '2821', '3663', '2730', '2857', '1922', '2049', '702', '1603', '1736', '3425', '3227', '2720', '2682', '1018', '3205', '1463', '307', '3521', '809', '3902', '418', '475', '2513', '2846', '3243', '3266', '1005', '3762', '2333', '1116', '593', '23', '2915', '1060', '1252', '1943', '1025', '1283', '1865', '1079', '429', '3409', '3270', '2861', '1831', '926', '1886', '2607', '3378', '1839', '1410', '3213', '696', '3516', '3576', '3865', '982', '417', '1557', '603', '1824', '1345', '3535', '1547', '2517', '1123', '446', '304', '1814', '1656', '3845', '1928', '3156', '2556', '3610', '1533', '2166', '1169', '621', '979', '2536', '884', '918', '3730', '1780', '595', '604', '122', '2976', '943', '2576', '3401', '1937', '146', '1361', '2829', '2639', '680', '3771', '1618', '2265', '837', '779', '120', '1999', '2014', '1948', '1856', '799', '3400', '1710', '1285', '458', '1114', '2957', '1034', '3379', '879', '3083', '1583', '3500', '3457', '1321', '3701', '2744', '3303', '432', '1782', '3350', '1548', '788', '531', '737', '2238', '3679', '321', '2898', '287', '102', '3752', '2367', '1909', '2090', '1935', '3234', '2415', '2216', '2795', '2532', '3412', '2535', '1652', '2045', '2932', '410', '2670', '2018', '993', '1258', '1985', '35', '140', '1265', '2037', '3011', '3904', '377', '1096', '447', '3873', '137', '2473', '1388', '859', '2865', '2656', '658', '291', '1440', '2569', '440', '2441', '281', '2659', '1556', '653', '2551', '3641', '2112', '616', '3714', '3231', '3222', '3643', '3463', '2787', '3459', '2510', '1268', '1256', '3188', '3308', '3092', '1684', '602', '684', '1757', '3180', '1594', '3318', '3799', '2181', '3635', '3507', '3137', '3449', '3095', '336', '636', '3216', '1253', '538', '1027', '3890', '1112', '967', '1509', '3364', '2274', '2206', '656', '2914', '3614', '214', '747', '1023', '3185', '1707', '848', '2883', '1648', '1630', '1035', '3637', '916', '3178', '2782', '2908', '1235', '2185', '1225', '3388', '1206', '2304', '1464', '2093', '1402', '1351', '3558', '451', '3438', '3465', '1019', '261', '2048', '1120', '354', '419', '833', '2231', '1688', '3622', '762', '2951', '3241', '1310', '1617', '1513', '2853', '2450', '1075', '3856', '3724', '1881', '3070', '2820', '1003', '759', '3912', '3502', '2973', '299', '3087', '1687', '1117', '1133', '1373', '3407', '1596', '2983', '1330', '3282', '295', '3002', '1546', '3547', '2776', '828', '650', '3906', '1031', '2007', '52', '3297', '3021', '2031', '3909', '2767', '3263', '1681', '1527', '436', '3609', '2534', '2743', '2230', '129', '329', '2822', '3421', '339', '461', '3443', '2566', '619', '3235', '3031', '490', '1006', '1755', '558', '394', '1698', '487', '2164', '1733', '629', '1081', '1050', '2856', '1053', '827', '3393', '3359', '3022', '178', '677', '3542', '1152', '2019', '1387', '987', '215', '2337', '3013', '1295', '3287', '1544', '865', '1384', '1857', '1850', '2355', '1760', '1041', '42', '426', '3041', '2588', '3036', '1809', '1721', '2554', '1324', '722', '3072', '132', '2719', '3357', '588', '2202', '3016', '1338', '1963', '2655', '1508', '1020', '1644', '812', '1004', '2791', '202', '2364', '2507', '741', '740', '2281', '311', '2702', '1595', '1308', '600', '1763', '2836', '1664', '1', '2229', '3000', '2713', '373', '575', '89', '2913', '1751', '2463', '2641', '2528', '715', '2139', '962', '1436', '897', '1132', '2605', '1749', '800', '3802', '2644', '3386', '1666', '1343', '1978', '3014', '2318', '3252', '2095', '3349', '1054', '790', '2361', '3343', '2600', '3897', '231', '228', '1536', '2440', '3846', '2834', '1877', '805', '3814', '1484', '3279', '1280', '1286', '3190', '2468', '1460', '2366', '615', '3804', '2236', '423', '3214', '1674', '2434', '1615', '2425', '3272', '878', '81', '103', '2604', '700', '707', '1244', '3077', '1927', '1552', '2179', '2190', '3456', '3294', '1246', '599', '3101', '727', '2287', '3527', '2663', '1565', '3749', '1848', '2862', '2810', '1397', '2081', '1979', '344', '860', '2984', '2043', '1017', '2868', '2634', '1367', '1659', '2407', '2522', '2344', '1021', '851', '1030', '3518', '59', '694', '720', '3651', '608', '3108', '292', '264', '2243', '1530', '3469', '597', '3704', '484', '3224', '3496', '2444', '48', '1255', '3544', '1369', '3309', '3347', '1503', '2161', '1606', '869', '3766', '3453', '2456', '1456', '1426', '279', '2416', '66', '2335', '3833', '1511', '633', '1731', '965', '220', '1190', '147', '1754', '3736', '3161', '1104', '54', '1826', '1777', '652', '2442', '3913', '612', '3631', '699', '56', '392', '948', '1562', '2071', '2073', '2710', '3194', '757', '3806', '71', '657', '3529', '2329', '2814', '3052', '2097', '1955', '3696', '1989', '3372', '3316', '78', '2775', '3082', '2435', '3688', '3489', '983', '2310', '3288', '2672', '3199', '3189', '872', '570', '1370', '1811', '3454', '669', '1748', '152', '294', '2893', '978', '2755', '2204', '750', '3458', '2129', '3555', '1930', '2177', '1153', '191', '3872', '1507', '753', '131', '2212', '1126', '3670', '1973', '1904', '2723', '3027', '1205', '2016', '11', '3047', '1278', '3523', '1182', '1941', '2300', '723', '3831', '3218', '1353', '3686', '2770', '1408', '168', '3043', '3573', '1796', '3758', '3061', '985', '18', '945', '924', '3860', '2039', '3377', '712', '3683', '3848', '1515']


print("MSL for training : ", train_ids_P)
print("MSL for testing : ", test_ids_P)
print("MER for training : ", train_ids_V)
print("MER for testing : ", test_ids_V)
DATASET_P = 'MSL'
DATASET_V = 'MER'
train_set = ISPRS_dataset(train_ids_P, train_ids_V, DATASET_P, DATASET_V, 
                          DATA_FOLDER_P, DATA_FOLDER_V, LABEL_FOLDER_P, LABEL_FOLDER_V, 
                          Depth_FOLDER_P, Depth_FOLDER_V, cache=CACHE)

train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE)

print("Date OK!!!!")

LEARNING_RATE = 2.5e-4
MOMENTUM = 0.9
WEIGHT_DECAY = 0.0005
LEARNING_RATE_D = 1e-4
LAMBDA_ADV_MAIN = 0.001
LAMBDA_ADV_AUX = 0.0002
LAMBDA_DECOMP = 0.01
LAMBDA_SEG_MAIN = 1.0
LAMBDA_SEG_AUX = 0.1
print('LAMBDA_DECOMP: ', LAMBDA_DECOMP)
optimizer = optim.SGD(model.parameters(),
                        lr=LEARNING_RATE,
                        momentum=MOMENTUM,
                        weight_decay=WEIGHT_DECAY)

# discriminators' optimizers
optimizer_d_aux = optim.Adam(d_aux.parameters(), lr=LEARNING_RATE_D,
                                betas=(0.9, 0.99))
optimizer_d_main = optim.Adam(d_main.parameters(), lr=LEARNING_RATE_D,
                                betas=(0.9, 0.99))
optimizer_d_aux_depth = optim.Adam(d_aux_depth.parameters(), lr=LEARNING_RATE_D,
                                betas=(0.9, 0.99))
optimizer_d_main_depth = optim.Adam(d_main_depth.parameters(), lr=LEARNING_RATE_D,
                                betas=(0.9, 0.99))

# labels for adversarial training
source_label = 0
target_label = 1


def test(test_ids, all=False, stride=WINDOW_SIZE[0], batch_size=BATCH_SIZE, window_size=WINDOW_SIZE):
    # Use the network on the test set
    test_images = (1 / 255 * np.asarray(io.imread(DATA_FOLDER_V.format(id)), dtype='float32') for id in test_ids)
    test_labels = (np.asarray(io.imread(LABEL_FOLDER_V.format(id)), dtype='uint8') for id in test_ids)
    eroded_labels = (convert_from_color(io.imread(LABEL_FOLDER_V.format(id))) for id in test_ids)

    # eroded_labels = (convert_from_color(io.imread(ERODED_FOLDER.format(id))) for id in test_ids)
    all_preds = []
    all_gts = []

    # Switch the network to inference mode
    model.eval()
    with torch.no_grad():
        for img, gt, gt_e in tqdm(zip(test_images, test_labels, eroded_labels), total=len(test_ids), leave=False):
            pred = np.zeros(img.shape[:2] + (N_CLASSES,))

            total = count_sliding_window(img, step=stride, window_size=window_size) // batch_size
            for i, coords in enumerate(
                    tqdm(grouper(batch_size, sliding_window(img, step=stride, window_size=window_size)), total=total,
                            leave=False)):

                # Build the tensor
                image_patches = [np.copy(img[x:x + w, y:y + h]).transpose((2, 0, 1)) for x, y, w, h in coords]
                image_patches = np.asarray(image_patches)
                image_patches = Variable(torch.from_numpy(image_patches).cuda(), volatile=True)

                # Do the inference
                _, pred2, _, _= model(image_patches)
                outs = F.softmax(pred2, dim=1)
                outs = outs.data.cpu().numpy()

                # Fill in the results array-
                for out, (x, y, w, h) in zip(outs, coords):
                    out = out.transpose((1, 2, 0))
                    pred[x:x + w, y:y + h] += out
                del (outs)

            pred = np.argmax(pred, axis=-1)
            clear_output()
            all_preds.append(pred)
            all_gts.append(gt_e)

            clear_output()
            # Compute some metrics
            # metrics(pred.ravel(), gt_e.ravel())
    accuracy = metrics(np.concatenate([p.ravel() for p in all_preds]),
                       np.concatenate([p.ravel() for p in all_gts]).ravel())
    model.train()
    if all:
        return accuracy, all_preds, all_gts
    else:
        return accuracy









attention_mechanism1 = SFF(9).cuda()  # 对应pred1
attention_mechanism2 = SFF(9).cuda() # 对应pred2

def train(epochs, start_save_epoch, save_epoch, weights=WEIGHTS):
    weights = weights.cuda()
    MIoU_best = 0.0
    iter = 0
    model.train()
    d_aux.train()
    d_main.train()
    d_aux_depth.train()
    d_main_depth.train()
    attention_mechanism1.train()
    attention_mechanism2.train()

    for epoch in range(1, epochs + 1):
        # print(f"开始第 {epoch}/{epochs} 轮训练")
        start_time = time.time()
        for batch_idx, (images, labels, depth_s, images_t, labels_t, depth_t)  in enumerate(train_loader):
            optimizer.zero_grad()
            adjust_learning_rate(optimizer, (epoch - 1) * (10000 / BATCH_SIZE) + batch_idx, epochs * (10000 / BATCH_SIZE))

            optimizer_d_aux.zero_grad()
            optimizer_d_main.zero_grad()
            optimizer_d_aux_depth.zero_grad()
            optimizer_d_main_depth.zero_grad()

            adjust_learning_rate_D(optimizer_d_aux, (epoch - 1) * (10000 / BATCH_SIZE) + batch_idx, epochs * (10000 / BATCH_SIZE))
            adjust_learning_rate_D(optimizer_d_main, (epoch - 1) * (10000 / BATCH_SIZE) + batch_idx, epochs * (10000 / BATCH_SIZE))

            adjust_learning_rate_D(optimizer_d_aux_depth, (epoch - 1) * (10000 / BATCH_SIZE) + batch_idx,
                                   epochs * (10000 / BATCH_SIZE))
            adjust_learning_rate_D(optimizer_d_main_depth, (epoch - 1) * (10000 / BATCH_SIZE) + batch_idx,
                                   epochs * (10000 / BATCH_SIZE))

            #源域训练
            images = Variable(images).cuda()
            depth_s = Variable(depth_s).float().cuda()

            depth_s = depth_s.repeat(1, 3, 1, 1)  # 形状变为 [batch_size, 6, 256, 256]
        
            pred1, pred2, f_dix, f_dsx = model(images)
            loss_seg1 = loss_calc(pred1, labels, weights)
            loss_seg2 = loss_calc(pred2, labels, weights)
            
            

            fused_features_s1 = attention_mechanism1(pred1, depth_s)  # pred1与深度图融合
            fused_features_s2 = attention_mechanism2(pred2, depth_s)  # pred2与深度图融合

            
            # plt.figure(figsize=(18, 8))  # 调整宽度以显示四组图

            # plt.subplot(4, 6, 1)
            # plt.imshow(images[0].detach().cpu().permute(1, 2, 0).numpy())  # 将原图显示为RGB格式
            # plt.title('Original Image')
            # plt.colorbar()

            # for i in range(6):
            #     # 显示深度图 depth_s 在第二列
            #     plt.subplot(4, 6, i + 7)
            #     plt.imshow(depth_s[0, i].detach().cpu().numpy(), cmap='viridis')
            #     plt.title(f'Depth S - Channel {i+1}')
            #     plt.colorbar()

            #     # 显示 pred1 的特征图在第三列
            #     plt.subplot(4, 6, i + 13)
            #     plt.imshow(pred2[0, i].detach().cpu().numpy(), cmap='viridis')
            #     plt.title(f'Pred1 - Channel {i+1}')
            #     plt.colorbar()

            #     # 显示融合后的特征图在第四列
            #     plt.subplot(4, 6, i + 19)
            #     plt.imshow(fused_features_s2[0, i].detach().cpu().numpy(), cmap='viridis')
            #     plt.title(f'Fused S1 - Channel {i+1}')
            #     plt.colorbar()

            # plt.tight_layout()
            # plt.show()
            
            # 目标域数据
            images_t = Variable(images_t).cuda()
            depth_t = Variable(depth_t).float().cuda()

            depth_t = depth_t.repeat(1, 3, 1, 1)  # 形状变为 [batch_size, 6, 256, 256]


            pred_target1, pred_target2, f_diy, f_dsy = model(images_t, mode='t')
            
            # 融合目标域的深度图
            fused_features_t1 = attention_mechanism1(pred_target1, depth_t)
            fused_features_t2 = attention_mechanism2(pred_target2, depth_t)
            # print(f"目标域深度图融合完成")

            # 2. 判别未融合的分割图与深度图融合后的分割图
            D_out1_orig = d_aux(prob_2_entropy(F.softmax(pred_target1, dim=1)))
            D_out2_orig = d_main(prob_2_entropy(F.softmax(pred_target2, dim=1)))
            # print(f"未融合的分割图判别完成")

            D_out1_fused = d_aux_depth(prob_2_entropy(F.softmax(fused_features_t1, dim=1)))
            D_out2_fused = d_main_depth(prob_2_entropy(F.softmax(fused_features_t2, dim=1)))
            # print(f"融合后的分割图判别完成")

            loss_adv_target1_orig = bce_loss(D_out1_orig, source_label)
            loss_adv_target2_orig = bce_loss(D_out2_orig, source_label)

            loss_adv_target1_fused = bce_loss(D_out1_fused, source_label)
            loss_adv_target2_fused = bce_loss(D_out2_fused, source_label)
            # print(f"对抗损失计算完成")

            # discrepancy losses
            loss_base = multi_discrepancy(f_dix, f_diy)
            loss_detail = multi_discrepancy(f_dsx, f_dsy)
            # print(f"差异损失计算完成")

            # # 源域分割图与深度图融合后进行判别
            # D_out1_fused_s = d_aux(prob_2_entropy(F.softmax(fused_features_s1, dim=1)))
            # D_out2_fused_s = d_main(prob_2_entropy(F.softmax(fused_features_s2, dim=1)))
            # # print(f"源域分割图与深度图融合判别完成")

            # # 源域损失计算
            # loss_adv_source1_fused = bce_loss(D_out1_fused_s, source_label)
            # loss_adv_source2_fused = bce_loss(D_out2_fused_s, source_label)
            # # print(f"源域对抗损失计算完成")

            # 总损失
            loss = (LAMBDA_SEG_MAIN * loss_seg2
                + LAMBDA_SEG_AUX * loss_seg1

                # + LAMBDA_ADV_MAIN * (loss_adv_target2_orig  )
                # + LAMBDA_ADV_AUX * (loss_adv_target1_orig  )

                # + LAMBDA_ADV_MAIN * (loss_adv_target2_orig+ loss_adv_target2_fused  )
                # + LAMBDA_ADV_AUX * (loss_adv_target1_orig + loss_adv_target1_fused )

                + LAMBDA_ADV_MAIN * (loss_adv_target2_orig  )
                + LAMBDA_ADV_AUX * (loss_adv_target1_orig  + loss_adv_target1_fused)

                + LAMBDA_DECOMP * (loss_base + loss_detail))
            loss.backward()
            # print(f"损失反向传播完成")

            # train D
            # bring back requires_grad
            for param in d_aux.parameters():
                param.requires_grad = True

            for param in d_main.parameters():
                param.requires_grad = True

            for param in d_aux_depth.parameters():
                param.requires_grad = True

            for param in d_main_depth.parameters():
                param.requires_grad = True

            # 1. 源域训练
            # train with source
            pred1 = pred1.detach()
            pred2 = pred2.detach()

            # 判别源域未融合的特征图
            D_out1_unfused_s = d_aux(prob_2_entropy(F.softmax(pred1, dim=1)))
            D_out2_unfused_s = d_main(prob_2_entropy(F.softmax(pred2, dim=1)))

            loss_D1_unfused_s = bce_loss(D_out1_unfused_s, source_label)
            loss_D2_unfused_s = bce_loss(D_out2_unfused_s, source_label)

            # 判别源域融合后的特征图
            fused_features_s1 = fused_features_s1.detach()
            fused_features_s2 = fused_features_s2.detach()

            D_out1_fused_s = d_aux_depth(prob_2_entropy(F.softmax(fused_features_s1, dim=1)))
            D_out2_fused_s = d_main_depth(prob_2_entropy(F.softmax(fused_features_s2, dim=1)))

            loss_D1_fused_s = bce_loss(D_out1_fused_s, source_label)
            loss_D2_fused_s = bce_loss(D_out2_fused_s, source_label)

            # 源域损失：未融合与融合后的损失相加
            # loss_D1 = (loss_D1_unfused_s + loss_D1_fused_s) / 2
            # loss_D2 = (loss_D2_unfused_s + loss_D2_fused_s) / 2

            # loss_D1 = (loss_D1_unfused_s ) / 2
            # loss_D2 = (loss_D2_unfused_s ) / 2

            loss_D1 = (loss_D1_unfused_s +loss_D1_fused_s) / 2
            loss_D2 = (loss_D2_unfused_s ) / 2

            # 反向传播源域损失
            loss_D1.backward()
            loss_D2.backward()

            # 2. 目标域训练
            # train with target
            pred_target1 = pred_target1.detach()
            pred_target2 = pred_target2.detach()

            # 判别目标域未融合的特征图
            D_out1_unfused_t = d_aux(prob_2_entropy(F.softmax(pred_target1, dim=1)))
            D_out2_unfused_t = d_main(prob_2_entropy(F.softmax(pred_target2, dim=1)))
            loss_D1_unfused_t = bce_loss(D_out1_unfused_t, target_label)
            loss_D2_unfused_t = bce_loss(D_out2_unfused_t, target_label)

            # 判别目标域融合后的特征图
            fused_features_t1 = fused_features_t1.detach()
            fused_features_t2 = fused_features_t2.detach()
            D_out1_fused_t = d_aux_depth(prob_2_entropy(F.softmax(fused_features_t1, dim=1)))
            D_out2_fused_t = d_main_depth(prob_2_entropy(F.softmax(fused_features_t2, dim=1)))
            loss_D1_fused_t = bce_loss(D_out1_fused_t, target_label)
            loss_D2_fused_t = bce_loss(D_out2_fused_t, target_label)

            # 目标域损失：未融合与融合后的损失相加
            # loss_D1 = (loss_D1_unfused_t + loss_D1_fused_t) / 2
            # loss_D2 = (loss_D2_unfused_t + loss_D2_fused_t) / 2

            # loss_D1 = (loss_D1_unfused_t ) / 2
            # loss_D2 = (loss_D2_unfused_t ) / 2

            loss_D1 = (loss_D1_unfused_t + loss_D1_fused_t ) / 2
            loss_D2 = (loss_D2_unfused_t ) / 2

            # 反向传播目标域损失
            loss_D1.backward()
            loss_D2.backward()

            # 更新优化器
            optimizer.step()
            optimizer_d_aux.step()
            optimizer_d_main.step()
            optimizer_d_aux_depth.step()
            optimizer_d_main_depth.step()


            if iter % 100 == 0:
                clear_output()
                pred = np.argmax(pred_target2.data.cpu().numpy()[0], axis=0)
                gt = labels_t.data.cpu().numpy()[0]
                end_time = time.time()
                print('Train (epoch {}/{}) [{}/{} ({:.0f}%)] lr: {:.12f} lr_D: {:.12f} Loss: {:.6f} Loss_Base: {:.6f} Loss_Detail: {:.6f} Loss_D1: {:.6f} Loss_D2: {:.6f} Accuracy: {:.2f}% Timeuse: {:.2f}'.format(
                    epoch, epochs, batch_idx, len(train_loader),
                    100. * batch_idx / len(train_loader), optimizer.state_dict()['param_groups'][0]['lr'], optimizer_d_aux.state_dict()['param_groups'][0]['lr'],
                    loss_seg2.data, loss_base.data, loss_detail.data, loss_D1.data, loss_D2.data, accuracy(pred, gt), end_time - start_time))
                start_time = time.time()
            iter += 1
            del (images, labels, images_t, labels_t, loss, loss_base, loss_detail, loss_D1, loss_D2)

        if epoch >= start_save_epoch and epoch % save_epoch == 0:
            start_time = time.time()
            MIoU = test(test_ids_V, all=False, stride=128)
            end_time = time.time()
            print('Test Stide_32 time use: ', end_time - start_time)
            start_time = time.time()
            if MIoU > MIoU_best:
                torch.save(model.state_dict(), '/data5/GLGAN/result_xiugai/MSL_MER/CGA_baoliu_pred1/MSL_MER_epoch{}_{}'.format(epoch, MIoU))
                MIoU_best = MIoU
    print("Train Done!!")

# train(100, 1, 1)





model.load_state_dict(torch.load('/data5/GLGAN/result_xiugai/MSL_MER/yuanshi/MSL_MER_epoch17_0.4654287662672052'))
acc, all_preds, all_gts = test(test_ids_V, all=True, stride=128)
print("Acc: ", acc)

